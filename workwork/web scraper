import requests
from bs4 import BeautifulSoup
import sqlite3
import threading
import queue
import time

# 数据库初始化
def init_db():
    conn = sqlite3.connect("scraper.db")
    cursor = conn.cursor()
    cursor.execute('''CREATE TABLE IF NOT EXISTS articles (
                      id INTEGER PRIMARY KEY AUTOINCREMENT,
                      title TEXT,
                      link TEXT)''')
    conn.commit()
    conn.close()

# 爬取函数
def fetch_page(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=5)
        if response.status_code == 200:
            return response.text
    except requests.RequestException as e:
        print(f"请求失败: {e}")
    return None

# 解析网页内容
def parse_articles(html):
    soup = BeautifulSoup(html, "html.parser")
    articles = []
    for item in soup.select("h2 a"):
        title = item.get_text()
        link = item.get("href")
        if link and not link.startswith("http"):
            link = "https://example.com" + link
        articles.append((title, link))
    return articles

# 保存数据到数据库
def save_to_db(articles):
    conn = sqlite3.connect("scraper.db")
    cursor = conn.cursor()
    cursor.executemany("INSERT INTO articles (title, link) VALUES (?, ?)", articles)
    conn.commit()
    conn.close()

# 任务队列
task_queue = queue.Queue()

# 线程工作函数
def worker():
    while not task_queue.empty():
        url = task_queue.get()
        print(f"爬取: {url}")
        html = fetch_page(url)
        if html:
            articles = parse_articles(html)
            save_to_db(articles)
        task_queue.task_done()

# 主函数
def main():
    init_db()
    base_url = "https://example.com/news?page="
    num_pages = 10
    num_threads = 5

    for i in range(1, num_pages + 1):
        task_queue.put(base_url + str(i))

    threads = []
    for _ in range(num_threads):
        t = threading.Thread(target=worker)
        t.start()
        threads.append(t)
    
    for t in threads:
        t.join()
    
    print("爬取完成！")

if __name__ == "__main__":
    main()
